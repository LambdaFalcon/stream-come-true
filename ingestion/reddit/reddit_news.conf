# This coniguration polls reddit for articles linking to the following domains
# nytimes.com, foxnews.com, bbc.co.uk, abcnews.go.com
# It ingests them into the reddit_news index using reddits unique id to avoid duplicates
input {
  http_poller {
    urls => {
      "nytimes.com" => "https://www.reddit.com/domain/nytimes.com/new/.json"
      "foxnews.com" => "https://www.reddit.com/domain/foxnews.com/new/.json"
      "bbc.co.uk" => "https://www.reddit.com/domain/bbc.co.uk/new/.json"
      "abcnews.go.com" => "https://www.reddit.com/domain/abcnews.go.com/new/.json"
      
  }
  schedule => {every => "10s"}
  request_timeout => 5
  }
}

filter {
    split {
        field => "[data][children]"
    }
    mutate {
        add_field => {"all_data" => "%{[data][children][data]}"}
    }
    prune {
        whitelist_names => ["^all_data$"]
      }
    json {
        source =>"all_data"
        target =>"data"
    }
    prune {
        whitelist_names => ["^data$"]
      }
    date {
        match => ["[data][created_utc]","UNIX"]
    }
    #adding usefull fields to the topp level so we can eventually drop the nonusefull data
    mutate {
        add_field => {"title" => "%{[data][title]}"}
        add_field => {"subreddit_id" => "%{[data][subreddit_id]}"}
        add_field => {"subreddit_name_prefixed" => "%{[data][subreddit_name_prefixed]}"}
        add_field => {"subreddit_subscribers" => "%{[data][subreddit_subscribers]}"}
        #stored in the http_poller meta
        add_field=> {"domain" => "%{[@metadata][name]}"}
        #sometimes there is a subdomain of the ones we are looking fore like
        add_field => {"full_domain" => "%{[data][domain]}"}
        add_field => {"creation_time" =>  "%{[@timestamp]}"}
    } 
    
}

output {
    elasticsearch {
        hosts => ["rhea1.inf.usi.ch:9200"]
        index => "reddit_news"
        document_id => "%{[data][id]}"
    }
}
